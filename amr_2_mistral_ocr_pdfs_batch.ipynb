{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/royam0820/LLM_OCR/blob/main/amr_2_mistral_ocr_pdfs_batch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Snd1KBOoVL2w"
      },
      "outputs": [],
      "source": [
        "# Make sure you have the dependencies installed\n",
        "!pip install -q mistralai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from mistralai import Mistral\n",
        "\n",
        "# Fetch the API key securely\n",
        "api_key = userdata.get('MISTRAL_API_KEY')\n",
        "\n",
        "# Set it in the environment without exposing it\n",
        "if api_key:\n",
        "    os.environ[\"MISTRAL_API_KEY\"] = api_key\n",
        "else:\n",
        "    raise ValueError(\"MISTRAL_API_KEY not found. Make sure it is set in Colab.\")\n",
        "\n",
        "# Initialize Mistral client\n",
        "client = Mistral(api_key=os.environ[\"MISTRAL_API_KEY\"])\n",
        "print(\"Mistral API Key loaded successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxufLvdZWmnc",
        "outputId": "008cf84a-64be-41ee-a729-2b1210f20f86"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mistral API Key loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WfoVOUk0VL2y"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import base64\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from mistralai import Mistral, DocumentURLChunk\n",
        "from mistralai.models import OCRResponse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dl-w1WuqVL2z"
      },
      "outputs": [],
      "source": [
        "# Path configuration\n",
        "INPUT_DIR = Path(\"pdfs_to_process\")   # Folder where the user places the PDFs to be processed\n",
        "DONE_DIR = Path(\"pdfs-done\")            # Folder where processed PDFs will be moved\n",
        "OUTPUT_ROOT_DIR = Path(\"ocr_output\")    # Root folder for conversion results\n",
        "\n",
        "# Ensure directories exist\n",
        "INPUT_DIR.mkdir(exist_ok=True)\n",
        "DONE_DIR.mkdir(exist_ok=True)\n",
        "OUTPUT_ROOT_DIR.mkdir(exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VIOvW7wuVL2z"
      },
      "outputs": [],
      "source": [
        "def replace_images_in_markdown(markdown_str: str, images_dict: dict) -> str:\n",
        "    \"\"\"\n",
        "    This converts base64 encoded images directly in the markdown...\n",
        "    And replaces them with links to external images, so the markdown is more readable and organized.\n",
        "    \"\"\"\n",
        "    for img_name, base64_str in images_dict.items():\n",
        "        markdown_str = markdown_str.replace(f\"![{img_name}]({img_name})\", f\"![{img_name}]({base64_str})\")\n",
        "    return markdown_str\n",
        "\n",
        "def get_combined_markdown(ocr_response: OCRResponse) -> str:\n",
        "    \"\"\"\n",
        "    Part of the response from the Mistral API, which is an OCRResponse object...\n",
        "    And returns a single string with the combined markdown of all the pages of the PDF.\n",
        "    \"\"\"\n",
        "    markdowns: list[str] = []\n",
        "    for page in ocr_response.pages:\n",
        "        image_data = {}\n",
        "        for img in page.images:\n",
        "            image_data[img.id] = img.image_base64\n",
        "        markdowns.append(replace_images_in_markdown(page.markdown, image_data))\n",
        "\n",
        "    return \"\\n\\n\".join(markdowns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nk-8UbEqVL2z"
      },
      "outputs": [],
      "source": [
        "def process_pdf(pdf_path: Path):\n",
        "    # Process all PDFs in INPUT_DIR\n",
        "    # - Important to be careful with the number of PDFs, as the Mistral API has a usage limit\n",
        "    #   and it could cause errors by exceeding the limit.\n",
        "\n",
        "    # PDF base name\n",
        "    pdf_base = pdf_path.stem\n",
        "    print(f\"Processing {pdf_path.name} ...\")\n",
        "\n",
        "    # Output folders\n",
        "    output_dir = OUTPUT_ROOT_DIR / pdf_base\n",
        "    output_dir.mkdir(exist_ok=True)\n",
        "    images_dir = output_dir / \"images\"\n",
        "    images_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    # PDF -> OCR\n",
        "    with open(pdf_path, \"rb\") as f:\n",
        "        pdf_bytes = f.read()\n",
        "\n",
        "    uploaded_file = client.files.upload(\n",
        "        file={\n",
        "            \"file_name\": pdf_path.name,\n",
        "            \"content\": pdf_bytes,\n",
        "        },\n",
        "        purpose=\"ocr\"\n",
        "    )\n",
        "\n",
        "    signed_url = client.files.get_signed_url(file_id=uploaded_file.id, expiry=1)\n",
        "\n",
        "    ocr_response = client.ocr.process(\n",
        "        document=DocumentURLChunk(document_url=signed_url.url),\n",
        "        model=\"mistral-ocr-latest\",\n",
        "        include_image_base64=True\n",
        "    )\n",
        "\n",
        "    # Save OCR in JSON\n",
        "    # (in case something fails it could be reused, but it is not used in the rest of the code)\n",
        "    ocr_json_path = output_dir / \"ocr_response.json\"\n",
        "    with open(ocr_json_path, \"w\", encoding=\"utf-8\") as json_file:\n",
        "        json.dump(ocr_response.dict(), json_file, indent=4, ensure_ascii=False)\n",
        "    print(f\"OCR response saved in {ocr_json_path}\")\n",
        "\n",
        "    # OCR -> Markdown prepared for Obsidian\n",
        "    # - That is, from base64 encoded images, it converts them to links to\n",
        "    #   external images and generates the images as such, in a subfolder.\n",
        "\n",
        "    global_counter = 1\n",
        "    updated_markdown_pages = []\n",
        "\n",
        "    for page in ocr_response.pages:\n",
        "        updated_markdown = page.markdown\n",
        "        for image_obj in page.images:\n",
        "\n",
        "            # base64 to image\n",
        "            base64_str = image_obj.image_base64\n",
        "            if base64_str.startswith(\"data:\"):\n",
        "                base64_str = base64_str.split(\",\", 1)[1]\n",
        "            image_bytes = base64.b64decode(base64_str)\n",
        "\n",
        "            # image extensions\n",
        "            ext = Path(image_obj.id).suffix if Path(image_obj.id).suffix else \".png\"\n",
        "            new_image_name = f\"{pdf_base}_img_{global_counter}{ext}\"\n",
        "            global_counter += 1\n",
        "\n",
        "            # save in subfolder\n",
        "            image_output_path = images_dir / new_image_name\n",
        "            with open(image_output_path, \"wb\") as f:\n",
        "                f.write(image_bytes)\n",
        "\n",
        "            # Update markdown with wikilink: ![[nombre_imagen]]\n",
        "            updated_markdown = updated_markdown.replace(\n",
        "                f\"![{image_obj.id}]({image_obj.id})\",\n",
        "                f\"![[{new_image_name}]]\"\n",
        "            )\n",
        "        updated_markdown_pages.append(updated_markdown)\n",
        "\n",
        "    final_markdown = \"\\n\\n\".join(updated_markdown_pages)\n",
        "    output_markdown_path = output_dir / \"output.md\"\n",
        "    with open(output_markdown_path, \"w\", encoding=\"utf-8\") as md_file:\n",
        "        md_file.write(final_markdown)\n",
        "    print(f\"Markdown generated in {output_markdown_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ey7-eAxvVL20",
        "outputId": "e7746c77-f855-434b-f338-6505291ab9a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing 2101.03961v3.pdf ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-2a372ab4ec39>:40: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  json.dump(ocr_response.dict(), json_file, indent=4, ensure_ascii=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OCR response saved in ocr_output/2101.03961v3/ocr_response.json\n",
            "Markdown generated in ocr_output/2101.03961v3/output.md\n",
            "2101.03961v3.pdf moved to pdfs-done\n",
            "Processing 2402.03300v3.pdf ...\n",
            "OCR response saved in ocr_output/2402.03300v3/ocr_response.json\n",
            "Markdown generated in ocr_output/2402.03300v3/output.md\n",
            "2402.03300v3.pdf moved to pdfs-done\n",
            "Processing 1804.07821v1.pdf ...\n",
            "OCR response saved in ocr_output/1804.07821v1/ocr_response.json\n",
            "Markdown generated in ocr_output/1804.07821v1/output.md\n",
            "1804.07821v1.pdf moved to pdfs-done\n"
          ]
        }
      ],
      "source": [
        "# Process all PDFs in INPUT_DIR\n",
        "# - Important to be careful with the number of PDFs, as the Mistral API has a usage limit\n",
        "#   and it could cause errors by exceeding the limit.\n",
        "\n",
        "pdf_files = list(INPUT_DIR.glob(\"*.pdf\"))      # Get all PDFs in pdfs_to_process. So make sure to place the PDFs there.\n",
        "if not pdf_files:\n",
        "    print(\"No PDFs to process.\")\n",
        "    exit()\n",
        "\n",
        "for pdf_file in pdf_files:\n",
        "    try:\n",
        "        process_pdf(pdf_file)\n",
        "        shutil.move(str(pdf_file), DONE_DIR / pdf_file.name)\n",
        "        print(f\"{pdf_file.name} moved to {DONE_DIR}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {pdf_file.name}: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "# Define the folder to zip\n",
        "folder_to_zip = '/content/ocr_output'\n",
        "\n",
        "# Define the output zip file name\n",
        "output_filename = 'ocr_output.zip'\n",
        "\n",
        "# Create the zip file, specifying the full output path\n",
        "shutil.make_archive(os.path.join(os.getcwd(), output_filename[:-4]), 'zip', folder_to_zip)\n",
        "# The above change ensures the archive is created with the specified name in the current working directory\n",
        "\n",
        "# Download the zip file using the full path\n",
        "files.download(os.path.join(os.getcwd(), output_filename))\n",
        "# The above change provides the full path to the download function."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "cDm40Vr1a8-A",
        "outputId": "c89c4291-990a-464a-c229-7852a060840e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3ca2e831-0e1d-4f84-959a-9dfb1e7ddaf3\", \"ocr_output.zip\", 2729695)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}