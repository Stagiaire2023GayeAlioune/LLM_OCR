{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/royam0820/LLM_OCR/blob/main/amr_2_mistral_ocr_pdfs_batch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "This notebook demonstrates how to use the **Mistral AI API** for performing OCR (Optical Character Recognition) on a batch of PDF documents.\n",
        "The main steps include:\n",
        "- Authenticating with the Mistral API\n",
        "- Loading and preprocessing PDF files\n",
        "- Extracting text using Mistral's language model\n",
        "- Optionally translating or formatting the output\n",
        "\n",
        "⚠️ **Note:** This notebook is designed for use in **Google Colab** and requires an environment variable `MISTRAL_API_KEY` to be set using `userdata`.\n",
        "\n",
        "Let's get started!\n"
      ],
      "metadata": {
        "id": "ct7veIvnoSlB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Snd1KBOoVL2w"
      },
      "outputs": [],
      "source": [
        "# Make sure you have the dependencies installed\n",
        "!pip install -q mistralai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from mistralai import Mistral\n",
        "\n",
        "# Fetch the API key securely\n",
        "api_key = userdata.get('MISTRAL_API_KEY')\n",
        "\n",
        "# Set it in the environment without exposing it\n",
        "if api_key:\n",
        "    os.environ[\"MISTRAL_API_KEY\"] = api_key\n",
        "else:\n",
        "    raise ValueError(\"MISTRAL_API_KEY not found. Make sure it is set in Colab.\")\n",
        "\n",
        "# Initialize Mistral client\n",
        "client = Mistral(api_key=os.environ[\"MISTRAL_API_KEY\"])\n",
        "print(\"Mistral API Key loaded successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxufLvdZWmnc",
        "outputId": "23372a44-83f2-4f01-d96d-698854e95909"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mistral API Key loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WfoVOUk0VL2y"
      },
      "outputs": [],
      "source": [
        "import json       # For reading/writing JSON data (e.g., saving OCR results)\n",
        "import base64     # For encoding/decoding file contents as base64 (used in API requests)\n",
        "import shutil     # For file operations like moving files and creating ZIP archives\n",
        "from pathlib import Path  # For handling filesystem paths in an object-oriented way\n",
        "\n",
        "# Mistral: main client for interacting with the Mistral API\n",
        "# DocumentURLChunk: helper class for structuring document inputs by URL\n",
        "from mistralai import Mistral, DocumentURLChunk\n",
        "\n",
        "# OCRResponse: data model representing the structured response from an OCR request\n",
        "from mistralai.models import OCRResponse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dl-w1WuqVL2z"
      },
      "outputs": [],
      "source": [
        "# Path configuration\n",
        "INPUT_DIR = Path(\"pdfs_to_process\")   # Folder where the user places the PDFs to be processed\n",
        "DONE_DIR = Path(\"pdfs-done\")            # Folder where processed PDFs will be moved\n",
        "OUTPUT_ROOT_DIR = Path(\"ocr_output\")    # Root folder for conversion results\n",
        "\n",
        "# Ensure directories exist\n",
        "INPUT_DIR.mkdir(exist_ok=True)\n",
        "DONE_DIR.mkdir(exist_ok=True)\n",
        "OUTPUT_ROOT_DIR.mkdir(exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_DIR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbQvTnwC0nRF",
        "outputId": "d408308e-a737-48b0-ea6b-dde886c61d5f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('pdfs_to_process')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "VIOvW7wuVL2z"
      },
      "outputs": [],
      "source": [
        "# function to convert base64 encoded images in the markdown,\n",
        "# it returns a modified markdown string where image references are replaced with base64 links\n",
        "# (i.e., ![img1](data:image/png;base64,...))\n",
        "\n",
        "def replace_images_in_markdown(markdown_str: str, images_dict: dict) -> str:\n",
        "    \"\"\"\n",
        "    This converts base64 encoded images directly in the markdown...\n",
        "    And replaces them with links to external images, so the markdown is more readable and organized.\n",
        "    \"\"\"\n",
        "    for img_name, base64_str in images_dict.items():\n",
        "        markdown_str = markdown_str.replace(f\"![{img_name}]({img_name})\", f\"![{img_name}]({base64_str})\")\n",
        "    return markdown_str\n",
        "\n",
        "\n",
        "# function to combine the markdown content from all pages of an OCR response into a single markdown string.\n",
        "def get_combined_markdown(ocr_response: OCRResponse) -> str:\n",
        "    \"\"\"\n",
        "    Part of the response from the Mistral API, which is an OCRResponse object...\n",
        "    And returns a single string with the combined markdown of all the pages of the PDF.\n",
        "    \"\"\"\n",
        "    markdowns: list[str] = []\n",
        "    # Iterate through each page in the OCR response\n",
        "    for page in ocr_response.pages:\n",
        "        image_data = {}\n",
        "        # Build a dictionary of image ID to base64 string for each image on the page\n",
        "        for img in page.images:\n",
        "            image_data[img.id] = img.image_base64\n",
        "        # Replace image references with actual base64 strings and append to list\n",
        "        markdowns.append(replace_images_in_markdown(page.markdown, image_data))\n",
        "    # Join all page markdowns with spacing between them\n",
        "    return \"\\n\\n\".join(markdowns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "nk-8UbEqVL2z"
      },
      "outputs": [],
      "source": [
        "# Process a single PDF file using the Mistral OCR API\n",
        "\n",
        "def process_pdf(pdf_path: Path):\n",
        "    # Process all PDFs in INPUT_DIR\n",
        "    # - Important to be careful with the number of PDFs, as the Mistral API has a usage limit\n",
        "    #   and it could cause errors by exceeding the limit.\n",
        "\n",
        "    # Extract the base name of the PDF (without extension) to use for folder naming\n",
        "    pdf_base = pdf_path.stem\n",
        "    print(f\"Processing {pdf_path.name} ...\")\n",
        "\n",
        "    # Create an output directory specific to this PDF\n",
        "    output_dir = OUTPUT_ROOT_DIR / pdf_base\n",
        "    output_dir.mkdir(exist_ok=True)\n",
        "    # Create a subdirectory to store extracted images from the OCR output\n",
        "    images_dir = output_dir / \"images\"\n",
        "    images_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    # Read the PDF file as binary\n",
        "    with open(pdf_path, \"rb\") as f:\n",
        "        pdf_bytes = f.read()\n",
        "\n",
        "    # Upload the PDF to Mistral's server for OCR processing\n",
        "    uploaded_file = client.files.upload(\n",
        "        file={\n",
        "            \"file_name\": pdf_path.name,\n",
        "            \"content\": pdf_bytes,\n",
        "        },\n",
        "        purpose=\"ocr\"   # Declare the purpose to get a temporary OCR-usable file ID\n",
        "    )\n",
        "\n",
        "    # Get a signed URL (valid for a short time) to access the uploaded file\n",
        "    signed_url = client.files.get_signed_url(file_id=uploaded_file.id, expiry=1)\n",
        "\n",
        "    # Send the document for OCR processing using the signed URL\n",
        "    ocr_response = client.ocr.process(\n",
        "        document=DocumentURLChunk(document_url=signed_url.url),   # Mistral expects a document URL\n",
        "        model=\"mistral-ocr-latest\",                               # Use the latest available OCR model\n",
        "        include_image_base64=True                                 # Include images as base64 in the result\n",
        "    )\n",
        "\n",
        "    # Save OCR result as JSON\n",
        "    # This can serve as a backup or for future analysis,\n",
        "    # (in case something fails it could be reused, but it is not used in the rest of the code)\n",
        "    ocr_json_path = output_dir / \"ocr_response.json\"\n",
        "    with open(ocr_json_path, \"w\", encoding=\"utf-8\") as json_file:\n",
        "        json.dump(ocr_response.dict(), json_file, indent=4, ensure_ascii=False)\n",
        "    print(f\"OCR response saved in {ocr_json_path}\")\n",
        "\n",
        "    # Prepare Markdown output with embedded image links suitable for Obsidian or other apps\n",
        "    # - Replaces base64 image references with links to saved local image files\n",
        "    # - Saves the actual image files to a subdirectory\n",
        "\n",
        "    global_counter = 1            # Used to create unique image filenames\n",
        "    updated_markdown_pages = []   # Stores the cleaned markdown content from each page\n",
        "\n",
        "    for page in ocr_response.pages:\n",
        "        updated_markdown = page.markdown    # Start with original markdown\n",
        "\n",
        "        for image_obj in page.images:\n",
        "            # Extract and decode base64 image\n",
        "            base64_str = image_obj.image_base64\n",
        "            if base64_str.startswith(\"data:\"):\n",
        "                # Strip off data URL prefix if present\n",
        "                base64_str = base64_str.split(\",\", 1)[1]\n",
        "            image_bytes = base64.b64decode(base64_str)\n",
        "\n",
        "            # Determine file extension (fallback to .png if none found)\n",
        "            ext = Path(image_obj.id).suffix if Path(image_obj.id).suffix else \".png\"\n",
        "            new_image_name = f\"{pdf_base}_img_{global_counter}{ext}\"\n",
        "            global_counter += 1\n",
        "\n",
        "            # Save decoded image to images folder\n",
        "            image_output_path = images_dir / new_image_name\n",
        "            with open(image_output_path, \"wb\") as f:\n",
        "                f.write(image_bytes)\n",
        "\n",
        "            # # Update markdown to use in-line links for local image references - ![[image.png]]\n",
        "            updated_markdown = updated_markdown.replace(\n",
        "                f\"![{image_obj.id}]({image_obj.id})\",\n",
        "                f\"![[{new_image_name}]]\"\n",
        "            )\n",
        "        # Add the updated markdown for this page to the list\n",
        "        updated_markdown_pages.append(updated_markdown)\n",
        "\n",
        "    # Combine all page markdowns and save to a single .md file\n",
        "    final_markdown = \"\\n\\n\".join(updated_markdown_pages)\n",
        "    output_markdown_path = output_dir / \"output.md\"\n",
        "    with open(output_markdown_path, \"w\", encoding=\"utf-8\") as md_file:\n",
        "        md_file.write(final_markdown)\n",
        "    print(f\"Markdown generated in {output_markdown_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ey7-eAxvVL20",
        "outputId": "4a9bca03-3fda-449d-a9aa-ec1e4917a28b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing 1804.07821v1.pdf ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-64fb5f89a243>:47: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  json.dump(ocr_response.dict(), json_file, indent=4, ensure_ascii=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OCR response saved in ocr_output/1804.07821v1/ocr_response.json\n",
            "Markdown generated in ocr_output/1804.07821v1/output.md\n",
            "1804.07821v1.pdf moved to pdfs-done\n",
            "Processing 2402.03300v3.pdf ...\n",
            "OCR response saved in ocr_output/2402.03300v3/ocr_response.json\n",
            "Markdown generated in ocr_output/2402.03300v3/output.md\n",
            "2402.03300v3.pdf moved to pdfs-done\n",
            "Processing 2101.03961v3.pdf ...\n",
            "OCR response saved in ocr_output/2101.03961v3/ocr_response.json\n",
            "Markdown generated in ocr_output/2101.03961v3/output.md\n",
            "2101.03961v3.pdf moved to pdfs-done\n"
          ]
        }
      ],
      "source": [
        "# Process all PDFs in the INPUT_DIR folder\n",
        "# ⚠️ Important: Mistral API has usage limits (e.g., requests per minute or daily caps)\n",
        "#    So processing too many PDFs at once may lead to errors or rate limiting.\n",
        "\n",
        "# The pdf documents to processed are in this directory: /content/pdfs_to_process\n",
        "\n",
        "pdf_files = list(INPUT_DIR.glob(\"*.pdf\"))\n",
        "if not pdf_files:     # Find all PDF files in the input directory\n",
        "    print(\"No PDFs to process.\")\n",
        "    exit()          # Exit early if no files are found\n",
        "\n",
        "# Iterate through each PDF and process it one by one\n",
        "for pdf_file in pdf_files:\n",
        "    try:\n",
        "        process_pdf(pdf_file)     # Run OCR and markdown/image export on the PDF\n",
        "        # Move the processed PDF to the DONE_DIR to avoid reprocessing\n",
        "        shutil.move(str(pdf_file), DONE_DIR / pdf_file.name)\n",
        "        print(f\"{pdf_file.name} moved to {DONE_DIR}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {pdf_file.name}: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyIPyy0vwrc8",
        "outputId": "58b33695-7508-4207-f1b9-c229e1cfe4d1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "# Define the folder to zip\n",
        "folder_to_zip = '/content/ocr_output'\n",
        "\n",
        "# Define the output zip file name\n",
        "output_filename = 'ocr_output.zip'\n",
        "\n",
        "# Create the zip file, specifying the full output path\n",
        "shutil.make_archive(os.path.join(os.getcwd(), output_filename[:-4]), 'zip', folder_to_zip)\n",
        "# The above change ensures the archive is created with the specified name in the current working directory\n",
        "\n",
        "# Download the zip file using the full path\n",
        "files.download(os.path.join(os.getcwd(), output_filename))\n",
        "# The above change provides the full path to the download function."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "cDm40Vr1a8-A",
        "outputId": "213c7ece-debe-44bc-fdd9-f1bd7912b77e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_db287730-933b-4704-9aef-5fe2527a1193\", \"ocr_output.zip\", 22)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ✅ Conclusion\n",
        "\n",
        "This notebook walked through a complete pipeline for batch OCR processing of PDF files using the **Mistral AI API** in Google Colab.  \n",
        "You learned how to:\n",
        "- Authenticate with the API securely\n",
        "- Process multiple PDFs from a specified folder\n",
        "- Save and format the OCR output in both JSON and Markdown\n",
        "- Export the results in a zipped archive\n",
        "\n",
        "This setup is ideal for automating large-scale document understanding tasks.\n",
        "You can now customize the workflow, improve prompt engineering, or extend it with translation/post-processing as needed.\n",
        "\n"
      ],
      "metadata": {
        "id": "cKOBsZfPx88w"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZeWWqLS0yaeb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}